---
title: "Final Report"
author: Aiden Streicher
date: May 11th, 2025
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(tidyverse)
library(dplyr)
library(readr)
library(formattable)

#This makes it so the IMDB vote numbers don't show in scientific notation
options(scipen=999)

imdb <- read.csv("imdb_top_250_tv.csv")
metacritic <- read.csv("metacritic_tv_scores.csv")
FA <- read.csv("FA_TV_Rankings.csv")

#This makes metacritic fit with the 1-10 rating system other websites use
metacritic$Score <- metacritic$Score / 10
```
My name is Aiden Streicher. I ended up doing this project solo.

My goal for this project is to find the best TV shows of all time according to the community. I was inspired by this photo that has made its way around the internet over the years.

```{r}
knitr::include_graphics("tv_rankings.png")
```

There are a lot of good TV shows at the top of the list, but there are also many issues with this rankings. Specifically I want to point out 3 issues I found and hope to improve on with this ranking.

1. It doesn't include any animated TV shows. There are a lot of animated shows that would likely appear in the top 10, but aren't included for some reason. The list is meant to be best TV shows of all time, not best live action TV shows of all time.

2. Some of the sources are poorly defined. In particular the last source seems to be some sort of "IMDB Vote?". This skews the rankings heavily to the top 2 and clearly doesn't belong in a ranking like this.

3. It doesn't take into account how many people voted on each site. If 1,000,000 people use IMDB for TV shows and 100,000 use metacritic user votes for the same thing, they are still weighted equally despite there being a lot less people on one site. I'll get into it later but this is the hardest issue to fix for a variety of reasons.

My goal is to build off this, and make my own list of the best TV shows of all time. 

The first step is gathering data and creating a list. I ended up deciding on a 2 step process to create this list, and broke down the sources into 3 categories. I plan to create an initial list of the top 50 TV shows using some of these sources, and then manually add the data for other sources after to adjust the pre-defined top 50 list. I will also not be using a few of the sources above. I'll explain each source and my reasoning below.

USING FOR INITIAL LIST:

These websites will be used to create the initial top 50 list.

IMDB- This is the best source when it comes to TV shows for a few reasons. It has the most users of any website and includes all types of TV shows. It also has an easy to access list of the top rated TV shows and is very easy to scape. One of my takeaways is that IMDB is the gold standard for data collection when looking at TV shows. I used this list: https://www.imdb.com/chart/toptv/?sort=user_rating%2Cdesc

Film Affinity- This is another website that has a decently sized user base and includes all types of TV shows. My biggest issue was scraping the data as it loaded in TV shows from a server, but once I got it figured out it worked great. I used this list: https://www.filmaffinity.com/us/ranking.php?rn=ranking_fa_series

Metacritic Metascore- This is different from the other 2 enteries I'm using as this provides a critical opinion rather than a user opinion. I think the variety helps, and it was also easy to scrape the data. The biggest problem is that it does not include any anime TV shows (although it does incldue western animated shows) so to account for this for the top 50 list it will look for the average rating of all websites with a score. I used this list: https://www.metacritic.com/browse/tv/?releaseYearMin=1910&releaseYearMax=2025&page=1

ADDING DATA AFTER:

These websites will have their ratings manually entered for the top 50 shows after the list is created. This is due to a variety of reasons depending on the website.

Rotten Tomatoes (Critic and User), Taste- The main reason why this wasn't included initially is because the sorting on this website is terrible. If you want to find a list of the best TV shows of all time for either critic or users you get a lot of results that are just 100% with a small number of votes. If you try to sort by most popular you just get a lot of new TV shows. Because of this I couldn't find a good list to get reliable data from. I'm still skeptical about including critic score because they give 100% to a LOT of shows, but I decided to leave it in. Taste also has sorting issues where it just shows the most popular new shows. Websites- https://www.rottentomatoes.com/, https://www.taste.io/

ReelGood, JustWatch, The Movie DB (TMDB)- These all fall into the same catagory where there was some problem with scraping the data. In the case of TMDB I was able to scrape the first 20 TV shows, but the rest were not avaliable. It also has a very strong anime and recency bias. In the case of JustWatch the JustWatch ratings are hidden in each TV's show page which makes scraping the data very difficult and outside my skill level. ReelGood I also had scraping issues with. Websites- https://www.themoviedb.org/tv/top-rated?language=en-US, https://reelgood.com/tv/curated/trending-picks?filter-sort=8, https://www.justwatch.com/us/guide/best-tv-shows-all-time

MyAnimeList- This is probably going to be the most controversial addition due to the fact that the website only has eastern animated shows (which will make up about 10-15% of the top 50). The biggest reason for adding it though is because it captures a VERY large amount of people that would otherwise go un-represented. For example the show Hunter x Hunter has ~178k votes from other sources, but has over 1.8 million votes on MAL. Considering there were a few sources that had no anime this felt like a good way to balance it out, although I think there are strong arguments for not adding it as well.

NOT USING:

IMDB Votes- I'm not fully sure what this is but based off the ratings it doesn't belong in this dataset. It may have been included to generate clicks on social media.

Other Sources- I considered adding other sources but they all had various problems which made me stick to the ones above. The main one I considered is Letterboxd but they only have some TV shows and not all in their database so they wern't fit for this project.

_____________________________________________________________________________________________________________

Now that we have our sources its time to create the initial list of the top 50 movies of all time!

If there were any scores listed as N/A that could be added I added them and ran it again until we got the most complete valid list possible.

I also made it so the minimum number of votes was 20,000 as a top TV show needs to be at least a little bit popular. This seems like a lot but most TV shows (even less popular ones) passed this bar no problem.

```{r}
#Make it so each database keeps their scores and votes (if applicable)
imdb <- imdb %>% rename(Imdb_Score = User.Score, Imdb_Votes = Number.of.Votes)
FA <- FA %>% rename(FA_Score = Score, FA_Votes = Number_Votes)
metacritic <- metacritic %>% rename(Metacritic_Score = Score)

#Merge the data
merged_data <- imdb %>%
  full_join(FA, by = "Title", relationship = "many-to-many") %>%
  full_join(metacritic, by = "Title", relationship = "many-to-many")

#We want each TV show to be in at least 2 of the lists (because of metacritics no anime)
merged_data <- merged_data %>%
  mutate(score_count = (!is.na(Imdb_Score)) + (!is.na(FA_Score)) + (!is.na(Metacritic_Score))) %>%
  filter(score_count >= 2)

#Get average score
merged_data <- merged_data %>%
  mutate(Average_Score = rowMeans(select(., Imdb_Score, FA_Score, Metacritic_Score), na.rm = TRUE))

#Make the number of votes numeric
merged_data <- merged_data %>%
  mutate(
    # Remove commas and convert to character (in case of factor), then to numeric.
    Imdb_Votes = as.numeric(gsub(",", "", as.character(Imdb_Votes))),
    FA_Votes   = as.numeric(gsub(",", "", as.character(FA_Votes)))
  )

#Get total number of votes
merged_data <- merged_data %>%
  mutate(Imdb_Votes = ifelse(is.na(Imdb_Votes), 0, Imdb_Votes),
         FA_Votes = ifelse(is.na(FA_Votes), 0, FA_Votes),
         Total_Votes = Imdb_Votes + FA_Votes)

#If there are less then 20,000 votes the TV show is filtered out
merged_data <- merged_data %>%
  filter(Total_Votes >= 20000)

#Rank by average score (highest first) and take the top 50 TV shows.
top_50 <- merged_data %>%
  arrange(desc(Average_Score)) %>%
  slice_head(n = 50)

#Replace missing scores in each source with "N/A"
top_50 <- top_50 %>%
  mutate(Average_Score = round(Average_Score, 2),
         Imdb_Score = ifelse(is.na(Imdb_Score), "N/A", as.character(Imdb_Score)),
         FA_Score = ifelse(is.na(FA_Score), "N/A", as.character(FA_Score)),
         Metacritic_Score = ifelse(is.na(Metacritic_Score), "N/A", as.character(Metacritic_Score))) %>%
  select(Title, Imdb_Score, Imdb_Votes, FA_Score, FA_Votes, Metacritic_Score, Average_Score, Total_Votes)

write_csv(top_50, "Top_50.csv")

head(top_50)
```

Now we have our initial list. Next I will manually add data for the other websites about these 50 shows.

Interesting Findings while doing this:

Dekalog has 31,000 ratings on IMDB. Despite this it only has 2,970 on every other website combined, which is the lowest number by far. 

Bluey has an average rating of 9.3 on IMDB but 8.0 on all the other websites, one of the biggest discrepancies. 

Severence scored a relatively low 7.9 on Rotten Tomatoes user score, one of its lowest scores given. Despite this it outperformed the average on every other non-core website.

Similarly Steins Gate scored abnormally poorly on both ReelGood and Justwatch, compared to its very high ratings on Rotten Tomatoes and MAL

House of Cards preformed very poorly on Rotten Tomatoes (both user and critic) and Taste, but preformed well on other websites.

Now that this is done we can see how all the websites like the top 50 shows.

```{r}
website_data <- read.csv("Full_Top50_Data.csv")

head(website_data)
```
From this I want to try out 3 different methods of rankings and compare them.

1. Take the average score from each source. The upside is this is straightforward and everything gets included. The downside is the representation is unbalanced. I'll call this the average_rating.

2. Get a "Score" from each website with users (website score * num users), add them up and divide by total number of viewers for that show. The upside is this is the best for general representation. The downside is that not every website reports how many users, and can't be included. I'll call this the user_rating.

3. Try and combine the two ideas by giving more popular websites more weight, while still including every website. This is a very subjective approach as I don't have a formula to determine the weight, but should be a good middle ground. I'll call this the weighted_rating.

First I'll create the first new ranking.

```{r}
#All the columns with "Users" in it are for counting total votes
rating_cols <- names(website_data)[!grepl("Users$", names(website_data))]
rating_cols <- setdiff(rating_cols, "Title")
user_cols <- names(website_data)[grepl("Users$", names(website_data))]

#Convert columns that aren't title to numeric
website_data <- website_data %>%
  mutate(across(all_of(rating_cols), ~ parse_number(na_if(as.character(.), "N/A"))))
website_data <- website_data %>%
  mutate(across(all_of(user_cols), ~ parse_number(na_if(as.character(.), "N/A"))))

#Get the avearge rating ignoring user counts
website_data <- website_data %>%
  rowwise() %>%
  mutate(average_rating = mean(c_across(all_of(rating_cols)), na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(average_rating = round(average_rating, 2))

#Put this information in a new csv
average_rating <- website_data %>% 
  select(Title, average_rating) %>%
  arrange(desc(average_rating))

write_csv(average_rating, "average_rating.csv")

head(average_rating)
```
This shifted things up quite a bit, with Planet Earth II moving down and Breaking Bad and Chernobyl moving up.

Next we'll do the same thing but count each users vote.

```{r}

#Every rating column with the number of user vote is in the format "Name" for the website rating
#and "Name_Users" for the number of votes that tv show got from the website

#This isolates these pairs so we can get a "User score" from each website
user_cols <- names(website_data)[grepl("_Users$", names(website_data))]
rating_cols <- sub("_Users$", "", user_cols)
paired_indices <- rating_cols %in% names(website_data)
user_cols <- user_cols[paired_indices]
rating_cols <- rating_cols[paired_indices]

#For each pair we want the number of votes * the rating
website_data <- website_data %>%
  rowwise() %>%
  mutate(
    #Total number of votes across all websites
    total_votes = sum(c_across(all_of(user_cols)), na.rm = TRUE),
    #Sum of the weighted "users" for each website
    weighted_sum = sum(c_across(all_of(rating_cols)) * c_across(all_of(user_cols)), na.rm = TRUE)
  ) %>%
  ungroup() %>%
  mutate(
    user_rating = if_else(total_votes > 0, round(weighted_sum / total_votes, 2), NA_real_)
  )

#Dataset with this user score
user_rating_csv <- website_data %>%
  select(Title, user_rating) %>%
  arrange(desc(user_rating))

write_csv(user_rating_csv, "user_rating.csv")

head(user_rating_csv)
```
In this one Breaking Bad remains king while Planet Earth II surges back up. Both The Wire and The Sopranos dropped out of the top 5 while Band of Brothers and Frieren is the first anime to crack it.

Lastly I want to try and do a weighted score. MAL and IMDB both contain by far the most users so their raitings will be 2.5x more important. Taste, Justwatch and FA both have more than the rest, so they will be factored by 1.25x. Lastly tomato critic and metacritic will also be weighted at 1.25x to give a bit more weight to the critics.

All these numbres could obviously be adjusted based on what you think is the right distriubution but lets see how it turns out.

```{r}

#The columns that have ratings
rating_cols <- c("Tomato_Critic", "Tomato_User", "Taste", "ReelGood", 
                 "JustWatch", "TMDB", "MAL", "FA", "Imdb", "Metacritic_Score")

#The weight for each rating source
weights <- c(
  "Tomato_Critic"    = 1.25,
  "Tomato_User"      = 1.0,
  "Taste"            = 1.25,
  "ReelGood"         = 1.0,
  "JustWatch"        = 1.25,
  "TMDB"             = 1.0,
  "MAL"              = 2.5,
  "FA"               = 1.25,
  "Imdb"             = 2.5,
  "Metacritic_Score" = 1.25
)

weighted_score <- website_data %>%
  rowwise() %>%
  mutate(
    weighted_sum = sum(c_across(all_of(rating_cols)) * weights[rating_cols], na.rm = TRUE),
    total_weight = sum(if_else(!is.na(c_across(all_of(rating_cols))), 
                               weights[rating_cols], 
                               0), na.rm = TRUE),
    weighted_rating = if_else(total_weight > 0, round(weighted_sum / total_weight, 2), NA_real_)
  ) %>%
  ungroup() %>%
  arrange(desc(weighted_rating)) %>%
  select(Title, weighted_rating)

#put this new data in a csv
write_csv(weighted_score, "weighted_score.csv")

head(weighted_score)
```

Now we have the data for all 3 of our different methods, along with the initial list of 50. Now I'll visualise it in a varety of different ways. First I want 2 lists, one of each shows rating per method, and one of its placement per method.

```{r}
#Combine all the scores
#Inital Rating is the first ratings, the others keep their name from earlier

#Overall Rating is the average of the 4 other ratings
combined_ratings <- average_rating %>%
  left_join(user_rating_csv, by = "Title") %>%
  left_join(top_50, by = "Title") %>%
  left_join(weighted_score, by = "Title") %>%
  rowwise() %>%
  mutate(Overall_Rating = round(mean(c(average_rating, user_rating, weighted_rating, Average_Score), na.rm = TRUE), 2)) %>%
  ungroup() %>%
  select(Title, Average_Score, average_rating, user_rating, weighted_rating, Overall_Rating)

combined_ratings <- combined_ratings %>%
  rename(initial_rating = Average_Score) %>%
  arrange(desc(Overall_Rating))

head(combined_ratings)
```
```{r}
#Now this is a list of the 1-50 rankings each show got
#on each list

placements <- combined_ratings %>%
  mutate(
    Rank_Simple   = min_rank(desc(average_rating)),
    Rank_User     = min_rank(desc(user_rating)),
    Rank_Weighted = min_rank(desc(weighted_rating)),
    Rank_Inital   = min_rank(desc(initial_rating))
  ) %>%
  # Compute an average rank
  mutate(Rank_Overall = round((Rank_Simple + Rank_User + Rank_Weighted+Rank_Inital) / 4, 1)) %>%
  select(Title, Rank_Inital, Rank_Simple, Rank_User, Rank_Weighted, Rank_Overall) %>%
  arrange(Rank_Overall)


head(placements)
```
Whats interesting is despite having a lower overall average rating, The Wire and Band of Brothers have a higher average list placement.

Lets make this data look nice. I'm using the formattable package. Green shows higher numbers and red lower numbers.

```{r}
formattable(combined_ratings, list(
  initial_rating = color_tile("red", "green"),
  average_rating = color_tile("red", "green"),
  user_rating   = color_tile("red", "green"),
  weighted_rating = color_tile("red", "green"),
  Overall_Rating = color_tile("red", "green")
))
```

We can do the same for the placements, this time lower numbers are better.

```{r}
formattable(placements, list(
  Rank_Initial   = color_tile("green", "red"),
  Rank_Simple   = color_tile("green", "red"),
  Rank_User     = color_tile("green", "red"),
  Rank_Weighted = color_tile("green", "red"),
  Rank_Overall  = color_tile("green", "red")
))
```

The last thing I want to do is put the rating data into a bar graph.

```{r myplot, fig.width=60, fig.height=60}

#Make it so the graph is sorted by overall rating
combined_ratings <- combined_ratings %>%
  mutate(Title = fct_reorder(Title, Overall_Rating, .desc = FALSE))

#Into long format
long_ratings <- combined_ratings %>%
  pivot_longer(
    cols = c(initial_rating, average_rating, user_rating, weighted_rating, Overall_Rating),
    names_to = "Method",
    values_to = "Rating"
  )

ggplot() +
#The background bar is the overall rating
  geom_col(data = filter(long_ratings, Method == "Overall_Rating"),
           aes(x = Title, y = Rating, group = Title),
           fill = "lightgrey",
           width = 0.9) +
#The bars over it are its individual scores on different methods
  geom_col(data = filter(long_ratings, Method != "Overall_Rating"),
           aes(x = Title, y = Rating, fill = Method),
           position = position_dodge(width = 0.9),
           width = 0.5) +
  coord_flip() +  # Horizontal bars
  labs(title = "Ratings by Method",
       subtitle = "The background bar is the Overall rating, the other bars are ratings by different methods.",
       x = "TV Show", 
       y = "Rating") +
  theme_minimal() +
  theme(
    plot.title    = element_text(size = 80, face = "bold"),
    plot.subtitle = element_text(size = 60),
    axis.title    = element_text(size = 60),
    axis.text     = element_text(size = 45),
    legend.title  = element_text(size = 60),
    legend.text   = element_text(size = 48)
  )
```

This gives us a better snapshot into how thinsg played out and visualizes some outliars. We can see that shows like Bluey and Dekalog outpreformed a lot in the user_rating, likely due to them having a lot more votes, and a higher rating on IMDB than any other website. Other shows like Death Note, Cowboy Bebop and Blue Eyed Samurai did much better on average_rating and weighted_rating. 
______________________________________________________

Overall there is no perfect way to rank TV shows. Even this method is flawed, as we are using ratings put onto the internet which means that there might be a bias about what type of people would do that in the first place.

Still there was a large sample size in both users and different websites. I think the list of TV shows put together is high quality and I'm happy with the end result.
